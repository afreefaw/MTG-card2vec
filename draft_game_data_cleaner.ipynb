{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a64c18-1f5e-42a2-b1a9-d17db44f6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94d790d-7958-4279-8c01-b6a2336748c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ariel\\\\Documents\\\\Coding\\\\repos\\\\MTG_card2vec\\\\scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69b2057-bd58-4fda-a53c-41754a129bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ariel\\\\Documents\\\\Coding\\\\repos'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "833bbec9-efad-49c6-952c-5678c81942ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - dynamic folder path\n",
    "path = getcwd() + '\\\\data\\\\draft'\n",
    "# path = 'C:/Users/Ariel/Documents/Coding/repos/MTG_card2vec/data/draft/'\n",
    "game_path = path +'game_data_public.SNC.PremierDraft.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79c0f1b5-1751-4a36-9923-0adba9a661ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Ariel\\\\Documents\\\\Coding\\\\repos\\\\MTG_card2vec\\\\exploratory_work\\\\data\\\\draftgame_data_public.SNC.PremierDraft.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#----Game data starts here----\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#get list of columns we want to keep, by excluding columns we don't want:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m game_data_sample \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#read in sample file to get columns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m drop_cols \u001b[38;5;241m=\u001b[39m game_data_sample\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mlist\u001b[39m(game_data_sample\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrawn_|opening_hand_\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# card count columns can be int 8. 3.7GB with int64, ~900mb with int8\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Ariel\\\\Documents\\\\Coding\\\\repos\\\\MTG_card2vec\\\\exploratory_work\\\\data\\\\draftgame_data_public.SNC.PremierDraft.csv'"
     ]
    }
   ],
   "source": [
    "#----Game data starts here----\n",
    "#get list of columns we want to keep, by excluding columns we don't want:\n",
    "game_data_sample = pd.read_csv(game_path,nrows=100) #read in sample file to get columns\n",
    "drop_cols = game_data_sample.columns.drop(list(game_data_sample.filter(regex='drawn_|opening_hand_')))\n",
    "\n",
    "# card count columns can be int 8. 3.7GB with int64, ~900mb with int8\n",
    "int8_cols = list(game_data_sample.filter(regex='deck_|sideboard_'))\n",
    "data_types = {}\n",
    "for x in int8_cols:\n",
    "    data_types[x] = 'int8'\n",
    "\n",
    "#read filtered game_data in chunks\n",
    "gen = pd.read_csv(game_path, chunksize = 100000, dtype = data_types)\n",
    "game_data = pd.concat((x[drop_cols] for x in gen), ignore_index=True)\n",
    "\n",
    "game_data.info(verbose=False, memory_usage=\"deep\") #show memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e17ee0c-384c-40a2-9a3b-c3dc02c28abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use the draft_id as the index\n",
    "game_data.set_index('draft_id', drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5935ee-c5d3-4791-b39c-3c9e342b28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column for number of games per match based on premier draft vs traditional (i.e., traditional is Best of 3)\n",
    "game_data['games_per_match'] = game_data['event_type'].apply(lambda x: 1 if x == 'PremierDraft' else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92723eb8-141a-4216-9de3-f6791e684ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find who won each match, first find # of games won in each match\n",
    "wins_in_match = game_data.groupby(['draft_id','match_number'])['won'].sum()\n",
    "wins_in_match.name = 'wins_in_match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af90908-433d-4cb2-a024-6739295d1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column for number of game wins in match\n",
    "game_data = game_data.join(wins_in_match, on = ['draft_id','match_number']).copy()\n",
    "#create column for whether they won the match\n",
    "game_data['won_match'] = game_data['wins_in_match'] > ( game_data['games_per_match'] / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf5c645-a414-410d-ad21-65dfdc0136af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of matches, match wins, losses for each draft ...\n",
    "\n",
    "# num_matches = game_data.groupby('draft_id')['rank'].count().copy()\n",
    "# num_matches.name = 'num_matches'\n",
    "\n",
    "num_matches = game_data.groupby('draft_id')['match_number'].max()\n",
    "num_matches.name = 'num_matches'\n",
    "match_wins = game_data.groupby('draft_id')['won_match'].sum()\n",
    "match_wins.name = 'match_wins'\n",
    "match_losses = num_matches - match_wins\n",
    "match_losses.name = 'match_losses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c30e72-2841-4e5b-972a-d27bb45df018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and add them as columns to game_data\n",
    "game_data = game_data.join(num_matches, how='left').copy()\n",
    "game_data = game_data.join(match_wins, how='left').copy()\n",
    "game_data = game_data.join(match_losses, how='left').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be16c46b-f346-4aad-bade-fcbe6cb3cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------Data validation-------------\n",
    "\n",
    "#Validate number of cards in deck and add 'deck_size' column\n",
    "deck_cols = list(game_data.filter(regex='deck_'))\n",
    "basic_land_cols = ['deck_Island','deck_Swamp','deck_Forest','deck_Plains','deck_Mountain']\n",
    "# game_data['deck_size'] = game_data[deck_cols].sum(axis=1)\n",
    "# num_cards_series = pd.Series(game_data[deck_cols].sum(axis=1))\n",
    "game_data.loc[:,'num_cards'] = pd.Series(game_data[deck_cols].sum(axis=1))\n",
    "game_data.loc[:,'num_basic_lands'] = pd.Series(game_data[basic_land_cols].sum(axis=1))\n",
    "if min(game_data['num_cards']) < 40:\n",
    "    raise ValueError('Found deck with less than 40 cards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e35218-97df-4bb6-92dd-7ea76570527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to get 1 row per draft_id, and we want to use only the first game of the final match in each draft.\n",
    "# (This is because by the final match they may have optimally adjusted their main deck vs sideboard,\n",
    "# but won't be strategically adjusting their deck to react to their opponent as they may in game 2 or 3 in a match)\n",
    "\n",
    "#Drop all games that are not the first game of the match\n",
    "game_data = game_data[game_data['game_number'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0577a0a3-ea11-4638-8f38-4f3b416b3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to final matches only\n",
    "game_data = game_data[game_data['match_number'] == game_data['num_matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb8f04b-c9e1-4344-80cd-43b070f046cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop suspicious drafts (More than 9 matches) There were only ~7 of these in the SNC premier draft set\n",
    "game_data = game_data.drop(game_data[game_data['num_matches'] > 9].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcc62378-e109-4579-9838-e4a349de83de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12026\n"
     ]
    }
   ],
   "source": [
    "#identify incomplete drafts\n",
    "inc_drafts = game_data[(game_data['match_losses'] < 3) * (game_data['match_wins'] < 7 )].copy()\n",
    "\n",
    "#Number of incomplete drafts\n",
    "print(len(inc_drafts))\n",
    "\n",
    "#drop them\n",
    "game_data.drop(inc_drafts.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e9809d-50e2-4e57-9348-58ffe341d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pool_ columns which show all the cards drafted (sum of deck and sideboard)\n",
    "\n",
    "deck_cols = list(game_data.filter(regex='deck_'))\n",
    "sideboard_cols = list(game_data.filter(regex='sideboard_'))\n",
    "assert(len(deck_cols) == len(sideboard_cols))\n",
    "\n",
    "pool_col_names = [x.replace('deck_', 'pool_') for x in deck_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9775f24-5455-4273-9a02-e2b8f0788c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_data = pd.DataFrame(\n",
    "    game_data.loc[:,deck_cols].to_numpy() + game_data.loc[:,sideboard_cols].to_numpy(),\n",
    "    index = game_data.index,\n",
    "    columns = pool_col_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09dd8022-91bc-458a-a133-e838be7ad614",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data = game_data.join(pool_data, how='left')\n",
    "\n",
    "#confirm (using island as a test) that after manipulation, each draft deck pool = deck + sideboard\n",
    "assert(all(game_data['pool_Island'] == game_data['deck_Island'] + game_data['sideboard_Island']))\n",
    "\n",
    "#but zero the land columns - we don't consider those as part of the pool\n",
    "for col in ['pool_Island','pool_Mountain','pool_Swamp','pool_Plains','pool_Forest']:\n",
    "    game_data.loc[:][col].values[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "074c6fbd-ff7c-4230-a4ca-18018d94ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 126955 entries, 0000057081cf48a5b8c0b21ea95997aa to fffffb56ac1e42c0b325860738f2ad8d\n",
      "Columns: 824 entries, expansion to pool_Ziatora, the Incinerator\n",
      "dtypes: bool(3), float64(1), int64(14), int8(798), object(8)\n",
      "memory usage: 187.2 MB\n"
     ]
    }
   ],
   "source": [
    "game_data.info(verbose=False, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b36a6a-07cf-42cb-98e7-1d8fc800c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "game_data.to_csv(path + 'output_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d038c-c2db-4efd-ba1c-6c356eceb6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
